{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files and store into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "    ls = []\n",
    "    for line in lines:\n",
    "        ls.append(line.strip())\n",
    "    f.close()\n",
    "    return ls\n",
    "\n",
    "dict_ls = readfile(\"dict.txt\")\n",
    "wiki_correct_ls = readfile(\"wiki_correct.txt\")\n",
    "wiki_misspell_ls = readfile(\"wiki_misspell.txt\")\n",
    "birkbeck_correct_ls = readfile(\"birkbeck_correct.txt\")\n",
    "birkbeck_misspell_ls = readfile(\"birkbeck_misspell.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Needleman-Wunsch Algorithm (Global Edit Distance) with Levenshtein Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform s1 to s2\n",
    "def edit_distance(s1,s2):\n",
    "    # Levenshteiin Distance (match,insert,delete,replace): the lower the better\n",
    "    m = 0\n",
    "    i = 1\n",
    "    d = 1\n",
    "    r = 1\n",
    "    \n",
    "    # init matrix\n",
    "    s1_len = len(s1)\n",
    "    s2_len = len(s2)\n",
    "    A = np.zeros((s2_len+1,s1_len+1))\n",
    "    A[0][0] = 0\n",
    "    for j in range(1, s2_len+1):\n",
    "        A[j][0] = j*i;  # insert\n",
    "    for k in range(1, s1_len+1):\n",
    "        A[0][k] = k*d;  # delete\n",
    "        \n",
    "    # filling in table\n",
    "    for j in range(1,s2_len+1):\n",
    "        for k in range(1,s1_len+1):\n",
    "            A[j][k] = min(A[j][k-1] + d,\n",
    "                          A[j-1][k] + i,\n",
    "                          A[j-1][k-1] + equal(s1[k-1],s2[j-1],m,r))\n",
    "\n",
    "    return A[s2_len,s1_len]\n",
    "    \n",
    "def equal(ch1,ch2,cost1,cost2):\n",
    "    if ch1 == ch2:\n",
    "        return cost1\n",
    "    else:\n",
    "        return cost2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best match for the word in dictionary according to the global edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match_edit_distance(target):\n",
    "    # init best matches\n",
    "    min_dist = editdistance.eval(target,dict_ls[0])\n",
    "    best_matches = [dict_ls[0]]\n",
    "    \n",
    "    for word in dict_ls[1:]:\n",
    "        if abs(len(word) - len(target)) > min_dist:  # not possible to be min_dist, skip\n",
    "            continue\n",
    "        dist = editdistance.eval(target,word)  # cal global edit distance\n",
    "        # replace if shorter distance\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            best_matches = [word]\n",
    "        elif dist == min_dist:\n",
    "            best_matches.append(word)\n",
    "    \n",
    "    return best_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best matches for the words in wiki data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_correction_dict = {}\n",
    "for word in wiki_misspell_ls:\n",
    "    if word not in wiki_correction_dict:\n",
    "        wiki_correction_dict[word] = best_match_edit_distance(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ngram import NGram as ngram\n",
    "ngram.compare('Ham','Spam',N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
