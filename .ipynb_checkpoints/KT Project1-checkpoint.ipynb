{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import Levenshtein as levenshtein\n",
    "import json\n",
    "import fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files and store into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "    ls = []\n",
    "    for line in lines:\n",
    "        ls.append(line.strip())\n",
    "    f.close()\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ls = readfile(\"dict.txt\")\n",
    "wiki_correct_ls = readfile(\"wiki_correct.txt\")\n",
    "wiki_misspell_ls = readfile(\"wiki_misspell.txt\")\n",
    "birkbeck_correct_ls = readfile(\"birkbeck_correct.txt\")\n",
    "birkbeck_misspell_ls = readfile(\"birkbeck_misspell.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best match(es) for the word in dictionary according to the global edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match_levenshtein(target):\n",
    "    # init best matches\n",
    "    min_dist = levenshtein.distance(target,dict_ls[0])\n",
    "    best_matches = [dict_ls[0]]\n",
    "    \n",
    "    for word in dict_ls[1:]:\n",
    "        if abs(len(word) - len(target)) > min_dist:  # not possible to be min_dist, skip\n",
    "            continue\n",
    "        dist = levenshtein.distance(target,word)  # cal global edit distance\n",
    "        # replace if shorter distance\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            best_matches = [word]\n",
    "        elif dist == min_dist:\n",
    "            best_matches.append(word)\n",
    "    \n",
    "    return best_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best matches for the words in wiki data sets according to levenshtein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_correction_dict = {}\n",
    "for word in wiki_misspell_ls:\n",
    "    if word not in wiki_correction_dict:\n",
    "        wiki_correction_dict[word] = best_match_levenshtein(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save correction results with global edit distance method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ged_correction.json', 'w') as fp:\n",
    "    json.dump(wiki_correction_dict, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric Implementation (Precision and Recall only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_eval(result_dict):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(500):\n",
    "        word = wiki_misspell_ls[i]\n",
    "        correction = wiki_correction_dict[word]\n",
    "\n",
    "        if wiki_correct_ls[i] in correction:\n",
    "            tp += 1\n",
    "            fp += len(correction) - 1\n",
    "        else:\n",
    "            fn += 1  # miss\n",
    "            fp += len(correction)\n",
    "\n",
    "    precision = tp*1.0 / (tp + fp)\n",
    "    recall = tp*1.0 / (tp + fn)\n",
    "\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('ged_correction.json', 'r') as fp:\n",
    "#    data = json.load(fp)\n",
    "#    fp.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best match(es) for the word in dictionary according to the soundex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match_soundex(target):\n",
    "    \n",
    "    soundex = fuzzy.Soundex(4)\n",
    "    target_soundex = soundex(target)\n",
    "    \n",
    "    best_matches = []\n",
    "    \n",
    "    for word in dict_ls:\n",
    "        print word\n",
    "        print soundex(word)\n",
    "        if (soundex(word) == target_soundex):  # same soundex\n",
    "            best_matches.append(word)\n",
    "    print best_matches\n",
    "    \n",
    "    return best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_correction_dict_soundex = {}\n",
    "for word in wiki_misspell_ls:\n",
    "    if word not in wiki_correction_dict_soundex:\n",
    "        wiki_correction_dict_soundex[word] = best_match_soundex(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundex = fuzzy.Soundex(4)\n",
    "soundex(\"aam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print wiki_dict_ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
